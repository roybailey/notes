# K8

* [kubernetes.io](https://kubernetes.io)
* [Kubernetes Documentation](https://kubernetes.io/docs/)
* [Kubernetes Documentation Concepts](https://kubernetes.io/docs/concepts/)
* [Kubernetes Documentation Setup](https://kubernetes.io/docs/setup/pick-right-solution/)
* [Kubernetes Documentation - Minikube Setup](https://kubernetes.io/docs/getting-started-guides/minikube/)
* [Oracle VirtualBox](https://www.virtualbox.org/)
* [OSBoxes VM images](http://osboxes.org/)
* [kubeadm installation instructions](https://kubernetes.io/docs/setup/independent/install-kubeadm/)
* [play-with-k8s.com](play-with-k8s.com)
* [yamllint.com](yamllint.com)

## Overview

* **NODES** = MACHINE, kubelet agent, network proxy, container runtime
* **CLUSTER** = GROUP OF NODES
* **MASTER** = NODE CONTROLLING CLUSTER, api server, cluster store, controller & scheduler, etcd (key/value store)
* **PODS** = RUN 1..N CONTAINERS, has own IP, tightly coupled services usually run together, often only one
* **REPLICASETS** = HOW TO REPLICATE A POD
* **SERVICES** = IP addressed load balancer, pods accessed via labelling
* **DEPLOYMENTS** = DEPLOYMENT OF REPLICASETS, versioning, rollback plan, deactivation

> Master **api-server** talks to worker/minion nodes with **kubelet** agent

### PODS

* [Pod Overview](https://kubernetes.io/docs/concepts/workloads/pods/pod-overview/)
* Run a container, or sometimes multiple tightly coupled containers e.g. main container and helper containers
* Each pod gets its own IP address internal to the Node (server) its running on

#### sample pod definition file

```
apiVersion: v1  
kind: Pod  
metadata:  
  name: myapp-pod  
  labels:  
    app: myapp  
spec:  
  containers:  
    - name: nginx-container  
      image: nginx
      env:
        - name: MYPASSWORD
          value: mysecretpassword
```

### CONTROLLERS & REPLICASETS

* Creates a template for a Pod and defines the replicas (number of instances)
* K8 will maintain desire number of instances

#### sample replicaset definition file

```
apiVersion: apps/v1  
kind: ReplicaSet
metadata:  
  name: myapp-replicaset  
  labels:  
    app: myapp-rs
spec:  
  replicas: 3
  template:
    metadata:  
      name: myapp-pod
      labels:  
        app: myapp
    containers:  
      - name: nginx-container  
        image: nginx
        env:
          - name: MYPASSWORD
            value: mysecretpassword
  selector:
    matchLabels:
      app: myapp
```

### DEPLOYMENT

* Versioned (revisions) and rollback capability

#### sample deployment definition file

```
apiVersion: apps/v1  
kind: Deployment
metadata:  
  name: myapp-replicaset  
  labels:  
    app: myapp-rs
spec:  
  replicas: 3
  template:
    metadata:  
      name: myapp-pod
      labels:  
        app: myapp
    containers:  
      - name: nginx-container  
        image: nginx
        env:
          - name: MYPASSWORD
            value: mysecretpassword
  selector:
    matchLabels:
      app: myapp
```

### Networking

* All containers/Pods can communicate to one another without NAT
* All nodes can communicate with all containers/Pods and vice versa without NAT

### Services

* Communication within and outside the application
* Connects services with other applications or users

#### Types

* NodePort - service listens to port on Pod and forwards to port on Node
* ClusterIP - virtual IP inside the cluster to enable communcation between services (e.g. front-end to backend services)
* LoadBalancer - load balance requests across your services (provisioned from cloud provider)

#### Ports

* TargetPort = Pod port
* Port = port on service itself listening to TargetPort
* NodePort = port on Node (server) itself, in range 30000-32767

#### sample service definition file

```
apiVersion: v1  
kind: Service  
metadata:  
  name: myapp-service  
spec:  
  type: NodePort  
  ports:  
    - targetPort: 80  
      port: 80  
      nodePort: 30008  
  selector:  
    app: myapp
```

#### ClusterIP



## Commands

| Command | Description |
|--|--|
| `kubectl run <name> --image=<namespace>/<image-name> --image-pull-policy=Never --port=<port-number>` | Runs a container image in a pod configured with port mapping |
| `kubectl get pods -o wide` | Gets running pods with extra details |
| `kubectl describe pods` | Gets running pods with verbose details |
| `kubectl get all` | Shows all deployments, replicasets and pods running |
| `kubectl expose deployment <pod-name> --type=NodePort` | Exposes node port for named pod |
| `minikube service <pod-name> --url` | Exposes pod url when running in minukube |
| `kubectl delete deployment <pod-name>` | Deletes running pod |
| `kubectl port-forward <pos-instance> 8080:5000` | Port forward to localhost |
| `kubectl create -f <k8 defintion file.yml> --record` | Create and run the k8 definition file, recording a revision |
| `kubectl replace -f <k8 defintion file.yml>` | Replace the running k8 definition file |
| `kubectl apply -f <k8 defintion file.yml>` | Apply the k8 definition file (updates) |
| `kubectl rollout status <k8 defintion file.yml>` | Show deployment rollout status |
| `kubectl rollout history <k8 defintion file.yml>` | Show deployment rollout history |
| `kubectl rollout undo <k8 defintion file.yml>` | Rollback deployment to previous revision |

## Application Tips

* `jib-maven-plugin` builds docker images, maintains same image if code not changed
* Memory needs to be set with `-XX:Percentage` of container setting
** 80% max to allow for ssh onto box
* `kubectl create secret` will create namespace key/value encrypted in container, mappable to env variables for applications
* Log to console in app, so k8 container can be tailed and controls file capture itself
* `Ingress` type to create canary rollout, sits above `Service` load balancer and forwards % (or other criteria) to different service/pods for cautious rollout

## Udemy Course Notes

### Bridged Adapter on VirtualBox doesn't connect to Mac WiFi

In VirtualBox, VM's Network panel, click on advanced, click on Port Forwarding button. In there set up a rule:
```
Host IP: 127.0.0.1
Host Port: 2222
Guest IP: 10.0.2.15
Guest Port: 22
```
Then enable ssh in the guest, and I'm able to connect from the host using:

`ssh -p 2222 osboxes@127.0.0.1`

### minikube for single local K8

* `brew cask install minikube`
* `minikube start`



<!--stackedit_data:
eyJoaXN0b3J5IjpbLTExMDUzMzg5NjUsLTEzNjYwOTY0MzMsOD
E2NjY1NDczLC0yMTI5MDY4NTExLC04MDk3MzU2ODMsLTc2MjQ5
NDg1MSw3NjUwODUxMTgsLTEzNzY2ODI3MDYsLTczMzAyMzIyLD
E2MzU4MDk4NDUsLTE0MjMyNDU3MjAsMzI4NTgzNTcsLTY1ODg4
MjU2NywtMTQxNzUyODE4MSwxNDk0NDIyNjk0LDIwMTIyNjU2MT
gsMzI0MjU5MzMzLDIwNTcxNDAzNzIsMTI5ODY4MzczMiwtODgx
OTI0NDYzXX0=
-->